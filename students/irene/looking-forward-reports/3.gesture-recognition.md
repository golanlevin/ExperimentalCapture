Gesture Recognition & Machine Learning
=======

For this week I've chosen to dig into a popular gesture recognition & machine learning toolkit for c++ developed by Nick Gillian. I was curious to see how Gillian made his technology accessible, open, and portable. What makes for a good creative coding toolkit?

## The Gesture Recognition Toolkit (GRT)

While a PhD student at the Sonic Arts Research Centre in Belfast, Nick Gillian developed a gesture recognition system for musician computer interaction. He'd been studying music technology for years. The toolkit that came out of his dissertation is a cross-platform, open-source, C++ machine learning library that has been specifically designed for real-time gesture recognition. It also comes with a GUI.

<img src="http://www.nickgillian.com/archive/wiki/grt/reference/GUI/GUIImage1.png" width="600px" />

The GRT is comprehensive. It includes almost a dozen different ML algorithms: Adaptive Naive Bayes Classifier, AdaBoost, K-Nearest Neighbor Classifier, Decision Tree, Dynamic Time Warping, MinDist, Support Vector Machine, etc. It also includes various feature extraction algorithms like low pass filter, moving average filter, class label filter, etc. 

The best thing about GRT is it's comprehensive wiki page. Gillian set it up so that an informed programmer or artist could jump into the code quickly. His tutorials include not just a basic overview of ML, but a useful set of coding examples, and tutorials. For example, he breaks the implementation into 6 steps that apply widely to any kind of machine learning pipeline. He also explains the general distinction between classification and regression problems (they each call for different kinds of algorithms).

Interestingly, I couldn't really find a performance or work of art featuring the GRT. 

* Github repo: <https://github.com/nickgillian/grt>

* Getting started wth machine learning and GRT: <http://www.nickgillian.com/wiki/pmwiki.php/GRT/GettingStarted>

* Tutorials: <http://www.nickgillian.com/wiki/pmwiki.php/GRT/Tutorials>

## Making code (& ML) accessible

Why GRT? I tried to find gestural toolkits  that were inteded for creative contexts, supported real-time performances, were open, and had some kind of online documentation. I wanted to investigate how accessible machine learning could be for non-specialist creative coders and artists. 

I think GRT sets a high bar for what a creative coding toolkit - or any kind of toolkit - should ideally be. It is well documented, easily accessible, comes with example code, and has been implemented across a few platforms (ofx, Processing, c++). Working through Gillian's tutorials you don't just learn how to implement GRT, you learn about machine learning in general. 

## Other toolkits

* Kinect2Gesture: gesture recognition app (and openFrameworks code) that uses Kinect V2: <https://github.com/genekogan/Kinect2Gesture>
* ofxLearn: General-purpose machine learning library for openFrameworks. <https://github.com/genekogan/ofxLearn>
* Georgia Tech Gesture Toolkit: <http://gt2k.cc.gatech.edu/>

# Looking Outwards 5: Displaced Dynamic Expression Regression for Real-time Facial Tracking and Animation

This Looking Outward reflects on the paper [Displaced Dynamic Expression Regression for Real-time Facial Tracking and Animation](LO5.pdf).

Th research team developed a method of matching user facial expressions in real time without requiring individual user calibration or a depth sensor \(The process uses only a standard web camera for input\).  The process relied on training the algorithm on not only a wide range of faces, but other helpful adaptive features like modifying the feature set dynamically.

This was a particularly interesting paper to read after my last looking outward, which also delt with real time shape tracking, but which was non face specific and used a depth camera.  While this group's goal of using only a webcam instead of depth tracking camera which is less widely available is interesting, I wonder how well it would adapt to objects that have less structured/defined features than faces.

